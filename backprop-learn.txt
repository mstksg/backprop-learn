-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Combinators and useful tools for ANNs using the backprop library
--   
--   See README.md
@package backprop-learn
@version 0.1.0.0

module Backprop.Learn

module Data.Type.Mayb
data Mayb :: (k -> Type) -> Maybe k -> Type
[N_] :: Mayb f  'Nothing
[J_] :: !(f a) -> Mayb f ( 'Just a)
fromJ_ :: Mayb f ( 'Just a) -> f a
maybToList :: Mayb f m -> Prod f (MaybeToList m)
listToMayb :: Prod f as -> Mayb f (ListToMaybe as)
data P :: k -> Type
[P] :: P a
type KnownMayb = Known (Mayb P)
knownMayb :: KnownMayb p => Mayb P p
zipMayb :: (forall a. f a -> g a -> h a) -> Mayb f m -> Mayb g m -> Mayb h m
zipMayb3 :: (forall a. f a -> g a -> h a -> i a) -> Mayb f m -> Mayb g m -> Mayb h m -> Mayb i m
class MaybeWit (c :: k -> Constraint) (m :: Maybe k)
maybeWit :: MaybeWit c m => Mayb (Wit1 c) m
splitTupMaybe :: forall f a b. (KnownMayb a, KnownMayb b) => (forall a' b'. (a ~  'Just a', b ~  'Just b') => f (T2 a' b') -> (f a', f b')) -> Mayb f (TupMaybe a b) -> (Mayb f a, Mayb f b)
tupMaybe :: forall f a b. () => (forall a' b'. (a ~  'Just a', b ~  'Just b') => f a' -> f b' -> f (T2 a' b')) -> Mayb f a -> Mayb f b -> Mayb f (TupMaybe a b)
instance forall k (f :: k -> *) (m :: GHC.Base.Maybe k). Data.Type.Mayb.MaybeC GHC.Show.Show (f Data.Type.Mayb.<$> m) => GHC.Show.Show (Data.Type.Mayb.Mayb f m)
instance forall k (c :: k -> GHC.Types.Constraint) (m :: GHC.Base.Maybe k). (Data.Type.Mayb.MaybeC c m, Type.Class.Known.Known (Data.Type.Mayb.Mayb Data.Type.Mayb.P) m) => Data.Type.Mayb.MaybeWit c m
instance forall k1 (k2 :: k1). Type.Class.Known.Known Data.Type.Mayb.P k2
instance forall k (m :: GHC.Base.Maybe k) (f :: k -> *). (Type.Class.Known.Known (Data.Type.Mayb.Mayb Data.Type.Mayb.P) m, Data.Type.Mayb.MaybeC GHC.Num.Num (f Data.Type.Mayb.<$> m)) => GHC.Num.Num (Data.Type.Mayb.Mayb f m)
instance forall k (m :: GHC.Base.Maybe k) (f :: k -> *). (Type.Class.Known.Known (Data.Type.Mayb.Mayb Data.Type.Mayb.P) m, Data.Type.Mayb.MaybeC GHC.Num.Num (f Data.Type.Mayb.<$> m), Data.Type.Mayb.MaybeC GHC.Real.Fractional (f Data.Type.Mayb.<$> m)) => GHC.Real.Fractional (Data.Type.Mayb.Mayb f m)
instance forall k (f :: k -> *). Type.Class.Known.Known (Data.Type.Mayb.Mayb f) 'GHC.Base.Nothing
instance forall a1 (f :: a1 -> *) (a2 :: a1). Type.Class.Known.Known f a2 => Type.Class.Known.Known (Data.Type.Mayb.Mayb f) ('GHC.Base.Just a2)
instance Type.Class.Higher.Functor1 Data.Type.Mayb.Mayb

module Backprop.Learn.Class

-- | Class for models that can be trained using gradient descent
--   
--   An instance <tt>l</tt> of <tt><a>Learn</a> a b</tt> is parameterized
--   by <tt>p</tt>, takes <tt>a</tt> as input, and returns <tt>b</tt> as
--   outputs. <tt>l</tt> can be thought of as a value containing the
--   <i>hyperparmaeters</i> of the model.
class Learn a b l | l -> a b where {
    type family LParamMaybe l :: Maybe Type;
    type family LStateMaybe l :: Maybe Type;
    type LParamMaybe l =  'Nothing;
    type LStateMaybe l =  'Nothing;
}

-- | Initialize parameters, given the hyperparameters in <tt>l</tt>.
--   
--   Default definition provided for models with no state.
initParam :: (Learn a b l, PrimMonad m) => l -> Gen (PrimState m) -> LParam_ m l

-- | Initialize parameters, given the hyperparameters in <tt>l</tt>.
--   
--   Default definition provided for models with no state.
initParam :: (Learn a b l, NoParam l) => l -> Gen (PrimState m) -> LParam_ m l

-- | Initialize state, given the hyperparameters in <tt>l</tt>.
--   
--   Default definition provided for models with no state.
initState :: (Learn a b l, PrimMonad m) => l -> Gen (PrimState m) -> LState_ m l

-- | Initialize state, given the hyperparameters in <tt>l</tt>.
--   
--   Default definition provided for models with no state.
initState :: (Learn a b l, NoState l) => l -> Gen (PrimState m) -> LState_ m l

-- | Run the model itself, deterministically.
--   
--   If your model has no state, you can define this conveniently using
--   <a>stateless</a>.
runLearn :: (Learn a b l, Reifies s W) => l -> LParam_ (BVar s) l -> BVar s a -> LState_ (BVar s) l -> (BVar s b, LState_ (BVar s) l)

-- | Run a model in stochastic mode.
--   
--   If model is inherently non-stochastic, a default implementation is
--   given in terms of <a>runLearn</a>.
--   
--   If your model has no state, you can define this conveniently using
--   <tt>statelessStoch</tt>.
runLearnStoch :: (Learn a b l, Reifies s W, PrimMonad m) => l -> Gen (PrimState m) -> LParam_ (BVar s) l -> BVar s a -> LState_ (BVar s) l -> m (BVar s b, LState_ (BVar s) l)

-- | The trainable parameter type of a model. Will be a compile-time error
--   if the model has no trainable parameters.
type LParam l = FromJust ( 'ShowType l :<>:  'Text " has no trainable parameters") (LParamMaybe l)

-- | The state type of a model. Will be a compile-time error if the model
--   has no state.
type LState l = FromJust ( 'ShowType l :<>:  'Text " has no trainable parameters") (LStateMaybe l)

-- | Constraint specifying that a given model has no trainabale parameters.
type NoParam l = LParamMaybe l ~  'Nothing

-- | Constraint specifying that a given model has no state.
type NoState l = LStateMaybe l ~  'Nothing

-- | Is <a>N_</a> if there is <tt>l</tt> has no trainable parameters;
--   otherwise is <a>J_</a> with <tt>f p</tt>, for trainable parameter type
--   <tt>p</tt>.
type LParam_ f l = Mayb f (LParamMaybe l)

-- | Is <a>N_</a> if there is <tt>l</tt> has no state; otherwise is
--   <a>J_</a> with <tt>f s</tt>, for state type <tt>s</tt>.
type LState_ f l = Mayb f (LStateMaybe l)

-- | Useful for defining <a>runLearn</a> if your model has no state.
stateless :: (a -> b) -> (a -> s -> (b, s))

-- | Useful for defining <a>runLearnStoch</a> if your model has no state.
statelessM :: Functor m => (a -> m b) -> (a -> s -> m (b, s))
runLearnStateless :: (Learn a b l, Reifies s W, NoState l) => l -> LParam_ (BVar s) l -> BVar s a -> BVar s b
runLearnStochStateless :: (Learn a b l, Reifies s W, NoState l, PrimMonad m) => l -> Gen (PrimState m) -> LParam_ (BVar s) l -> BVar s a -> m (BVar s b)
data Mayb :: (k -> Type) -> Maybe k -> Type
[N_] :: Mayb f  'Nothing
[J_] :: !(f a) -> Mayb f ( 'Just a)
fromJ_ :: Mayb f ( 'Just a) -> f a
type KnownMayb = Known (Mayb P)
knownMayb :: KnownMayb p => Mayb P p

module Backprop.Learn.Component.State

-- | Make a model stateless by converting the state to a trained parameter,
--   and dropping the modified state from the result.
--   
--   One of the ways to make a model stateless for training purposes.
--   Useful when used after <a>Unroll</a>. See <a>FixState</a>, as well.
--   
--   Its parameters are:
--   
--   <ul>
--   <li>If <tt>l</tt> has no parameter or state, nothing.</li>
--   <li>If <tt>l</tt> has parameters but no state, just the original
--   parameters.</li>
--   <li>If <tt>l</tt> has no parameters but state, just the initial
--   state.</li>
--   <li>If <tt>l</tt> has parameters and state, a <a>T2</a> of the
--   parameter and initial state.</li>
--   </ul>
--   
--   However, this is really only meant to be used with types that have
--   state. If used with a type with no state, this is essentially a
--   no-op/identity.
newtype DeState :: Type -> Type
[DeState] :: {getDestate :: l} -> DeState l

-- | Make a model stateless by pre-applying a fixed state and dropping the
--   modified state from the result.
--   
--   One of the ways to make a model stateless for training purposes.
--   Useful when used after <a>Unroll</a>. See <a>DeState</a>, as well.
--   
--   If used with a type with no state, is essentially a no-op/identity.
data FixState :: Maybe Type -> Type -> Type
[FS] :: {_fsLearn :: l, _fsInitState :: Mayb I s} -> FixState s l

-- | Unroll a stateful model into one taking a vector of sequential inputs.
--   
--   Useful when used before <a>DeState</a> or <a>FixState</a>. See
--   <a>UnrollDeState</a> and <a>UnrollFixState</a>.
newtype Unroll :: Nat -> Type -> Type
[Unroll] :: {getUnroll :: l} -> Unroll n l

-- | Unroll a stateful model into a stateless one taking a vector of
--   sequential inputs and treat the initial state as a trained parameter.
--   
--   <pre>
--   instance <a>Learn</a> a b l
--       =&gt; <a>Learn</a> (<a>Vector</a> n a) (<a>Vector</a> n b) (<a>UnrollDeState</a> n l)'
--   
--       type <a>LParamMaybe</a> (<a>UnrollFixState</a> n l) = 'TupMaybe (<a>LParamMaybe</a> l) (<a>LStateMaybe</a> l)
--       type <a>LStateMaybe</a> (<a>UnrollFixState</a> n l) = '<a>Nothing</a>
--   </pre>
type UnrollDeState n l = DeState (Unroll n l)

-- | Unroll a stateful model into a stateless one taking a vector of
--   sequential inputs and fix the initial state.
--   
--   <pre>
--   instance <a>Learn</a> a b l
--       =&gt; <a>Learn</a> (<a>Vector</a> n a) (<a>Vector</a> n b) (<a>UnrollFixState</a> n l)'
--   
--       type <a>LParamMaybe</a> (<a>UnrollFixState</a> n l) = <a>LParamMaybe</a> l
--       type <a>LStateMaybe</a> (<a>UnrollFixState</a> n l) = '<a>Nothing</a>
--   </pre>
type UnrollFixState n l = FixState (LParamMaybe l) (Unroll n l)
instance (Backprop.Learn.Class.Learn a b l, Backprop.Learn.Class.LStateMaybe l ~ s) => Backprop.Learn.Class.Learn a b (Backprop.Learn.Component.State.FixState s l)
instance (Backprop.Learn.Class.Learn a b l, Data.Type.Mayb.KnownMayb (Backprop.Learn.Class.LParamMaybe l), Data.Type.Mayb.KnownMayb (Backprop.Learn.Class.LStateMaybe l), Data.Type.Mayb.MaybeC GHC.Num.Num (Backprop.Learn.Class.LParamMaybe l), Data.Type.Mayb.MaybeC GHC.Num.Num (Backprop.Learn.Class.LStateMaybe l)) => Backprop.Learn.Class.Learn a b (Backprop.Learn.Component.State.DeState l)
instance (Backprop.Learn.Class.Learn a b l, GHC.TypeNats.KnownNat n, GHC.Num.Num a, GHC.Num.Num b) => Backprop.Learn.Class.Learn (Data.Vector.Sized.Vector n a) (Data.Vector.Sized.Vector n b) (Backprop.Learn.Component.State.Unroll n l)

module Backprop.Learn.Component.Function

-- | A <tt><a>ParamFunc</a> p a b</tt> is a parameterized function from
--   <tt>a</tt> to <tt>b</tt>, potentially with trainable parameter
--   <tt>p</tt>.
--   
--   A utility wrapper for a deterministic and stateless model.
data ParamFunc p a b
PF :: (forall m. PrimMonad m => Gen (PrimState m) -> Mayb m p) -> (forall s. Reifies s W => Mayb (BVar s) p -> BVar s a -> BVar s b) -> ParamFunc p a b
[_pfInit] :: ParamFunc p a b -> forall m. PrimMonad m => Gen (PrimState m) -> Mayb m p
[_pfFunc] :: ParamFunc p a b -> forall s. Reifies s W => Mayb (BVar s) p -> BVar s a -> BVar s b

-- | Convenient type synonym for a <a>ParamFunc</a> with parameters.
--   
--   Mostly made to be easy to construct/deconstruct with <a>PFP</a>,
--   <a>_pfpInit</a>, and <a>_pfpFunc</a>.
type ParamFuncP p = ParamFunc ( 'Just p)
_pfpInit :: () => ParamFuncP p a b -> forall (m :: * -> *). PrimMonad m => Gen PrimState m -> m p
_pfpFunc :: () => ParamFuncP p a b -> forall s. Reifies Type s W => BVar s p -> BVar s a -> BVar s b

-- | An unparameterized function. Has a <a>Category</a> instance.
--   
--   A <tt><a>FixedFunc</a> a b</tt> essentially the same as a:
--   
--   <pre>
--   forall s. <a>Reifies</a> s <a>W</a> =&gt; <a>BVar</a> s a -&gt; <a>BVar</a> s b
--   </pre>
--   
--   And the <a>FF</a> pattern (and <a>runFixedFunc</a> extractor) witness
--   this.
--   
--   It is usually better to just use the functions directly, with
--   combinators like <tt>Dimap</tt>, <tt>LMap</tt>, <tt>RMap</tt>,
--   <a>dimapPF</a>, <a>lmapPF</a>, <a>rmapPF</a>, etc. This is just
--   provided to let you work nicely with <a>ParamFunc</a> combinators.
type FixedFunc = ParamFunc  'Nothing
runFixedFunc :: () => FixedFunc a b -> forall s. Reifies Type s W => BVar s a -> BVar s b

-- | Utility function to make a <a>ParamFunc</a> that maps a parameterized
--   function over every item in the <a>R</a>. The parameter is shared
--   across the entire map, and trained.
paramMap :: KnownNat i => (forall m. PrimMonad m => Gen (PrimState m) -> Mayb m p) -> (forall s. Reifies s W => Mayb (BVar s) p -> BVar s Double -> BVar s Double) -> ParamFunc p (R i) (R i)

-- | Create a <a>ParamFunc</a> from any instance of <a>Learn</a> that does
--   not have state.
learnParam :: forall l a b. (Learn a b l, NoState l) => l -> ParamFunc (LParamMaybe l) a b

-- | Pre- and post-compose a <a>ParamFunc</a>
dimapPF :: (forall s. Reifies s W => BVar s a -> BVar s b) -> (forall s. Reifies s W => BVar s c -> BVar s d) -> ParamFunc p b c -> ParamFunc p a d

-- | Precompose a <a>ParamFunc</a>
lmapPF :: (forall s. Reifies s W => BVar s a -> BVar s b) -> ParamFunc p b c -> ParamFunc p a c

-- | Postcompose a <a>ParamFunc</a>
rmapPF :: (forall s. Reifies s W => BVar s b -> BVar s c) -> ParamFunc p a b -> ParamFunc p a c

-- | Compose two <a>ParamFunc</a>s sequentially
--   
--   TODO: rewrite using <a>TupMaybe</a>
compPF :: (Num p, Num q) => ParamFunc ( 'Just p) a b -> ParamFunc ( 'Just q) b c -> ParamFunc ( 'Just (T2 p q)) a c

-- | Compose two <a>ParamFunc</a>s in parallel
--   
--   TODO: rewrite using <a>TupMaybe</a>
parPF :: (Num p, Num q, Num a, Num b, Num c, Num d) => ParamFunc ( 'Just p) a c -> ParamFunc ( 'Just q) b d -> ParamFunc ( 'Just (T2 p q)) (T2 a b) (T2 c d)

-- | Compose two <a>ParamFuncP</a>s on lists.
(.-) :: forall ps qs a b c. (ListC (Num <$> ps), ListC (Num <$> qs), Known Length ps, Known Length qs) => ParamFuncP (T ps) b c -> ParamFuncP (T qs) a b -> ParamFuncP (T (ps ++ qs)) a c
infixr 9 .-

-- | The identity of <a>.-</a>
nilPF :: ParamFuncP (T '[]) a a

-- | <a>ParamFuncP</a> taking a singleton list; meant to be used with
--   <a>.-</a>
onlyPF :: forall p a b. (KnownMayb p, MaybeC Num p) => ParamFunc p a b -> ParamFuncP (T (MaybeToList p)) a b

-- | Binary step / heaviside step
--   
--   To use with vectors (<a>R</a>), use <a>vmap'</a>.
--   
--   &lt;math&gt;
step :: (Ord a, Num a) => a -> a

-- | Logistic function
--   
--   &lt;math&gt;
logistic :: Floating a => a -> a

-- | Softsign activation function
--   
--   &lt;math&gt;
softsign :: Fractional a => a -> a

-- | Rectified linear unit.
--   
--   To use with vectors (<a>R</a>), use <a>vmap'</a>.
--   
--   &lt;math&gt;
--   
--   <pre>
--   <a>reLU</a> = <a>preLU</a> 0
--   </pre>
reLU :: (Num a, Ord a) => a -> a

-- | SoftPlus
--   
--   &lt;math&gt;
softPlus :: Floating a => a -> a

-- | Bent identity
--   
--   &lt;math&gt;
bentIdentity :: Floating a => a -> a

-- | Sigmoid-weighted linear unit. Multiply <a>logistic</a> by its input.
--   
--   &lt;math&gt;
siLU :: Floating a => a -> a

-- | SoftExponential
--   
--   To use with vectors (<a>R</a>), use <a>vmap'</a>.
--   
--   &lt;math&gt;
softExponential :: (Floating a, Ord a) => a -> a -> a

-- | Sinc
--   
--   &lt;math&gt;
sinc :: (Floating a, Eq a) => a -> a

-- | Gaussian
--   
--   &lt;math&gt;
gaussian :: Floating a => a -> a

-- | Usable with functions like <a>*</a>, <a>isru</a>, etc. to turn them
--   into a form usable with <a>PFP</a>:
--   
--   <pre>
--   <a>liftUniform</a> (<a>*</a>)  :: <a>BVar</a> s <a>Double</a> -&gt; BVar s (<a>R</a> n) -&gt; BVar s (R n)
--   liftUniform <a>isru</a> :: BVar s Double -&gt; BVar s (R n) -&gt; BVar s (R n)
--   </pre>
--   
--   Basically turns a parmaeterized function on individual elements of
--   into one that shares the same parameter across all elements of the
--   vector.
liftUniform :: (Reifies s W, KnownNat n) => (BVar s (R n) -> r) -> BVar s Double -> r

-- | Inverse square root unit
--   
--   &lt;math&gt;
--   
--   See <a>liftUniform</a> to make this compatible with <a>PFP</a>.
--   
--   You can also just use this after partially applying it, to fix the
--   parameter (and not have it trained).
isru :: Floating a => a -> a -> a

-- | Parametric rectified linear unit
--   
--   To use with vectors (<a>R</a>), use <a>vmap'</a>.
--   
--   If scaling parameter is a fixed (and not learned) parameter, this is
--   typically called a leaky recitified linear unit (typically with Î± =
--   0.01).
--   
--   To use as a learned parameter:
--   
--   <pre>
--   <a>vmap</a> . <a>preLU</a> :: <a>BVar</a> s Double -&gt; <a>BVar</a> s (<a>R</a> n) -&gt; BVar s (R n)
--   </pre>
--   
--   This can be give directly to <a>PFP</a>.
--   
--   To fix the paramater ("leaky"), just partially apply a parameter:
--   
--   <pre>
--   <a>preLU</a> 0.01 :: <a>BVar</a> s (<a>R</a> n) -&gt; BVar s (R n)
--   </pre>
--   
--   &lt;math&gt;
preLU :: (Num a, Ord a) => a -> a -> a

-- | S-shaped rectified linear activiation unit
--   
--   See <a>sreLUPFP</a> for an uncurried and uniformly lifted version
--   usable with <a>PFP</a>.
--   
--   &lt;math&gt;
sreLU :: (Num a, Ord a) => a -> a -> a -> a -> a -> a

-- | An uncurried and uniformly lifted version of <a>sreLU</a> directly
--   usable with <a>PFP</a>.
sreLUPFP :: (KnownNat n, Reifies s W) => BVar s (T2 (T2 Double Double) (T2 Double Double)) -> BVar s (R n) -> BVar s (R n)

-- | Exponential linear unit
--   
--   To use as a learned parameter:
--   
--   <pre>
--   <a>vmap</a> . <a>eLU</a> :: <a>BVar</a> s Double -&gt; <a>BVar</a> s (<a>R</a> n) -&gt; BVar s (R n)
--   </pre>
--   
--   This can be give directly to <a>PFP</a>.
--   
--   To fix the paramater, just partially apply a parameter:
--   
--   <pre>
--   <a>eLU</a> 0.01 :: <a>BVar</a> s (<a>R</a> n) -&gt; BVar s (R n)
--   </pre>
--   
--   &lt;math&gt;
eLU :: (Floating a, Ord a) => a -> a -> a

-- | Inverse square root linear unit
--   
--   To use with vectors (<a>R</a>), use <a>vmap'</a>.
--   
--   &lt;math&gt;
isrLU :: (Floating a, Ord a) => a -> a -> a

-- | Adaptive piecewise linear activation unit
--   
--   See <a>aplPFP</a> for an uncurried version usable with <a>PFP</a>.
--   
--   &lt;math&gt;
apl :: (KnownNat n, KnownNat m, Reifies s W) => BVar s (L n m) -> BVar s (L n m) -> BVar s (R m) -> BVar s (R m)

-- | <a>apl</a> uncurried, to be directly usable with <a>PFP</a>.
aplPFP :: (KnownNat n, KnownNat m, Reifies s W) => BVar s (T2 (L n m) (L n m)) -> BVar s (R m) -> BVar s (R m)

-- | Softmax normalizer
softMax :: (KnownNat i, Reifies s W) => BVar s (R i) -> BVar s (R i)

-- | Maximum of vector.
--   
--   Compare to <a>norm_InfV</a>, which gives the maximum absolute value.
maxout :: (KnownNat n, Reifies s W) => BVar s (R n) -> BVar s Double
instance (GHC.Num.Num a, GHC.Num.Num b, Data.Type.Mayb.MaybeC GHC.Num.Num p, Data.Type.Mayb.KnownMayb p) => Backprop.Learn.Class.Learn a b (Backprop.Learn.Component.Function.ParamFunc p a b)
instance (Data.Type.Mayb.MaybeC GHC.Num.Num p, Data.Type.Mayb.KnownMayb p) => Control.Category.Category (Backprop.Learn.Component.Function.ParamFunc p)

module Backprop.Learn.Component.FullyConnected

-- | Fully connected feed-forward layer with bias. Parameterized by its
--   initialization distribution.
newtype FC (i :: Nat) (o :: Nat)
FC :: (forall m. PrimMonad m => Gen (PrimState m) -> m Double) -> FC
[_fcGen] :: FC -> forall m. PrimMonad m => Gen (PrimState m) -> m Double

-- | Construct an <tt><a>FC</a> i o</tt> using a given distribution from
--   the <i>statistics</i> library.
fc :: ContGen d => d -> FC i o

-- | Fully connected feed-forward layer parameters.
data FCP i o
FCP :: !(R o) -> !(L o i) -> FCP i o
[_fcBias] :: FCP i o -> !(R o)
[_fcWeights] :: FCP i o -> !(L o i)
fcBias :: Functor f => (R o -> f (R o)) -> FCP i o -> f (FCP i o)
fcWeights :: Functor f => (L o i -> f (L o k)) -> FCP i o -> f (FCP k o)

-- | Fully connected recurrent layer with bias.
--   
--   Parameterized by its initialization distributions, and also the
--   function to compute the new state from previous input.
data FCR (h :: Nat) (i :: Nat) (o :: Nat)
FCR :: (forall m. PrimMonad m => Gen (PrimState m) -> m Double) -> (forall m. PrimMonad m => Gen (PrimState m) -> m Double) -> (forall s. Reifies s W => BVar s (R o) -> BVar s (R h)) -> FCR
[_fcrGen] :: FCR -> forall m. PrimMonad m => Gen (PrimState m) -> m Double
[_fcrGenState] :: FCR -> forall m. PrimMonad m => Gen (PrimState m) -> m Double
[_fcrStore] :: FCR -> forall s. Reifies s W => BVar s (R o) -> BVar s (R h)

-- | Construct an <tt><a>FCR</a> h i o</tt> using a given distribution from
--   the <i>statistics</i> library.
fcr :: ContGen d => d -> (forall s. Reifies s W => BVar s (R o) -> BVar s (R h)) -> FCR h i o

-- | Fully connected feed-forward layer parameters.
data FCRP h i o
FCRP :: !(R o) -> !(L o i) -> !(L o h) -> FCRP h i o
[_fcrBias] :: FCRP h i o -> !(R o)
[_fcrInputWeights] :: FCRP h i o -> !(L o i)
[_fcrStateWeights] :: FCRP h i o -> !(L o h)
fcrBias :: Functor f => (R o -> f (R o)) -> FCRP h i o -> f (FCRP h i o)
fcrInputWeights :: Functor f => (L o i -> f (L o i')) -> FCRP h i o -> f (FCRP h i' o)
fcrStateWeights :: Functor f => (L o h -> f (L o h')) -> FCRP h i o -> f (FCRP h' i o)
instance GHC.Generics.Generic (Backprop.Learn.Component.FullyConnected.FCRP h i o)
instance GHC.Generics.Generic (Backprop.Learn.Component.FullyConnected.FCP i o)
instance (GHC.TypeNats.KnownNat h, GHC.TypeNats.KnownNat i, GHC.TypeNats.KnownNat o) => GHC.Num.Num (Backprop.Learn.Component.FullyConnected.FCRP h i o)
instance (GHC.TypeNats.KnownNat h, GHC.TypeNats.KnownNat i, GHC.TypeNats.KnownNat o) => Backprop.Learn.Class.Learn (Internal.Static.R i) (Internal.Static.R o) (Backprop.Learn.Component.FullyConnected.FCR h i o)
instance (GHC.TypeNats.KnownNat i, GHC.TypeNats.KnownNat o) => GHC.Num.Num (Backprop.Learn.Component.FullyConnected.FCP i o)
instance (GHC.TypeNats.KnownNat i, GHC.TypeNats.KnownNat o) => Backprop.Learn.Class.Learn (Internal.Static.R i) (Internal.Static.R o) (Backprop.Learn.Component.FullyConnected.FC i o)

module Backprop.Learn.Component.Dropout

-- | Dropout layer. Parameterized by dropout percentage (should be between
--   0 and 1).
--   
--   0 corresponds to no dropout, 1 corresponds to complete dropout of all
--   nodes every time.
newtype DO (n :: Nat)
DO :: Double -> DO
[_doRate] :: DO -> Double
instance GHC.TypeNats.KnownNat n => Backprop.Learn.Class.Learn (Internal.Static.R n) (Internal.Static.R n) (Backprop.Learn.Component.Dropout.DO n)

module Data.Type.NonEmpty
data NETup :: NonEmpty Type -> Type
[NET] :: a -> T as -> NETup (a :| as)
netHead :: Functor f => (a -> f b) -> NETup (a :| as) -> f (NETup (b :| as))
netTail :: Functor f => (T as -> f (T bs)) -> NETup (a :| as) -> f (NETup (a :| bs))
unNet :: NETup (a :| as) -> (a, T as)
netT :: NETup (a :| as) -> T (a : as)
tNet :: T (a : as) -> NETup (a :| as)
instance (GHC.Num.Num a, Type.Family.List.ListC (GHC.Num.Num Type.Family.List.<$> as), Type.Class.Known.Known Data.Type.Length.Length as) => GHC.Num.Num (Data.Type.NonEmpty.NETup (a 'Data.List.NonEmpty.:| as))

module Backprop.Learn.Component.Combinator

-- | Chain components linearly, retaining the ability to deconstruct at a
--   later time.
data Chain :: [Type] -> [Type] -> [Type] -> Type -> Type -> Type
[CNil] :: Chain '[] '[] '[] a a
[:~>] :: (Learn a b l, KnownMayb (LParamMaybe l), KnownMayb (LStateMaybe l)) => l -> Chain ls ps ss b c -> Chain (l : ls) (MaybeToList (LParamMaybe l) ++ ps) (MaybeToList (LStateMaybe l) ++ ss) a c

-- | Appending <a>Chain</a>
(~++) :: forall ls ms ps qs ss ts a b c. () => Chain ls ps ss a b -> Chain ms qs ts b c -> Chain (ls ++ ms) (ps ++ qs) (ss ++ ts) a c
chainParamLength :: Chain ls ps ss a b -> Length ps
chainStateLength :: Chain ls ps ss a b -> Length ss

-- | Data type representing trainable models.
--   
--   Useful for performant composition, but you lose the ability to
--   decompose parts.
data LearnFunc :: Maybe Type -> Maybe Type -> Type -> Type -> Type
[LF] :: {_lfInitParam :: forall m. PrimMonad m => Gen (PrimState m) -> Mayb m p, _lfInitState :: forall m. PrimMonad m => Gen (PrimState m) -> Mayb m s, _lfRunLearn :: forall q. Reifies q W => Mayb (BVar q) p -> BVar q a -> Mayb (BVar q) s -> (BVar q b, Mayb (BVar q) s), _lfRunLearnStoch :: forall m q. (PrimMonad m, Reifies q W) => Gen (PrimState m) -> Mayb (BVar q) p -> BVar q a -> Mayb (BVar q) s -> m (BVar q b, Mayb (BVar q) s)} -> LearnFunc p s a b
learnFunc :: Learn a b l => l -> LearnFunc (LParamMaybe l) (LStateMaybe l) a b

-- | Pre- and post-compose pure parameterless functions to a model.
--   
--   A <tt><a>Dimap</a> b c a d</tt> takes a model from <tt>b</tt> to
--   <tt>c</tt> and turns it into a model from <tt>a</tt> to <tt>d</tt>.
data Dimap :: Type -> Type -> Type -> Type -> Type -> Type
[DM] :: {_dmPre :: forall s. Reifies s W => BVar s a -> BVar s b, _dmPost :: forall s. Reifies s W => BVar s c -> BVar s d, _dmLearn :: l} -> Dimap b c a d l

-- | Pre-compose a pure parameterless function to a model.
--   
--   An <tt><a>LMap</a> b c a</tt> takes a model from <tt>b</tt> to
--   <tt>c</tt> and turns it into a model from <tt>a</tt> to <tt>c</tt>.
type LMap b c a = Dimap b c a c
lm :: (forall s. Reifies s W => BVar s a -> BVar s b) -> l -> LMap b c a l

-- | Post-compose a pure parameterless function to a model.
--   
--   An <tt><tt>Rmap</tt> a b c</tt> takes a model from <tt>a</tt> to
--   <tt>b</tt> and turns it into a model from <tt>a</tt> to <tt>c</tt>.
type RMap a b = Dimap a b a
rm :: (forall s. Reifies s W => BVar s b -> BVar s c) -> l -> RMap a b c l

-- | Compose two <a>LearnFunc</a> on lists.
(.~) :: forall ps qs ss ts a b c. (ListC (Num <$> ps), ListC (Num <$> qs), ListC (Num <$> ss), ListC (Num <$> ts), ListC (Num <$> (ss ++ ts)), Known Length ps, Known Length qs, Known Length ss, Known Length ts) => LearnFunc ( 'Just (T ps)) ( 'Just (T ss)) b c -> LearnFunc ( 'Just (T qs)) ( 'Just (T ts)) a b -> LearnFunc ( 'Just (T (ps ++ qs))) ( 'Just (T (ss ++ ts))) a c

-- | Identity of <a>.~</a>
nilLF :: LearnFunc ( 'Just (T '[])) ( 'Just (T '[])) a a

-- | <a>LearnFunc</a> with singleton lists; meant to be used with <a>.~</a>
onlyLF :: forall p s a b. (KnownMayb p, MaybeC Num p, KnownMayb s, MaybeC Num s) => LearnFunc p s a b -> LearnFunc ( 'Just (T (MaybeToList p))) ( 'Just (T (MaybeToList s))) a b
instance Backprop.Learn.Class.Learn b c l => Backprop.Learn.Class.Learn a d (Backprop.Learn.Component.Combinator.Dimap b c a d l)
instance (Backprop.Learn.Class.Learn b c l, Backprop.Learn.Class.Learn a b m, Data.Type.Mayb.KnownMayb (Backprop.Learn.Class.LParamMaybe l), Data.Type.Mayb.KnownMayb (Backprop.Learn.Class.LParamMaybe m), Data.Type.Mayb.KnownMayb (Backprop.Learn.Class.LStateMaybe l), Data.Type.Mayb.KnownMayb (Backprop.Learn.Class.LStateMaybe m), Data.Type.Mayb.MaybeC GHC.Num.Num (Backprop.Learn.Class.LParamMaybe l), Data.Type.Mayb.MaybeC GHC.Num.Num (Backprop.Learn.Class.LParamMaybe m), Data.Type.Mayb.MaybeC GHC.Num.Num (Backprop.Learn.Class.LStateMaybe l), Data.Type.Mayb.MaybeC GHC.Num.Num (Backprop.Learn.Class.LStateMaybe m)) => Backprop.Learn.Class.Learn a c (l Backprop.Learn.Component.Combinator.:.~ m)
instance Backprop.Learn.Class.Learn a b (Backprop.Learn.Component.Combinator.LearnFunc p s a b)
instance (Data.Type.Mayb.MaybeC GHC.Num.Num p, Data.Type.Mayb.MaybeC GHC.Num.Num s, Data.Type.Mayb.KnownMayb p, Data.Type.Mayb.KnownMayb s) => Control.Category.Category (Backprop.Learn.Component.Combinator.LearnFunc p s)
instance (Type.Family.List.ListC (GHC.Num.Num Type.Family.List.<$> ps), Type.Family.List.ListC (GHC.Num.Num Type.Family.List.<$> ss)) => Backprop.Learn.Class.Learn a b (Backprop.Learn.Component.Combinator.Chain ls ps ss a b)
